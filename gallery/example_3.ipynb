{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Fluorescence intensity and shape of phytoplankton cells\n",
    "\n",
    "In this example the goal is to detect phytoplankton cells in gray-channel images and use the obtained coordinates to measure texture traits (intensities and statistical moments) in fluorescence channels of the same images.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; flex-direction: row; text-align:left; gap: 10px;\"  class=\"row\">\n",
    "<div class=\"col-md-6\">\n",
    "<img src=\"_figures/ex3_before.jpg\">\n",
    "\n",
    "**Input** - Phytoplankton fluorescence. Each sample includes 1 brightfield gray scale image and 3 fluorescence images at different wavelengths.\n",
    "</div>\n",
    "<div class=\"col-md-6\">\n",
    "<img src=\"_figures/ex3_after.jpg\">\n",
    "\n",
    "**Results** - Phenopype `thresholding` function detects the contours of phytoplankton cells (green) and holes within (red).</div>\n",
    "</div>\n",
    "\n",
    "Images kindly provided by Irene Gallego and Anita Narwani."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "A plate reader creates four images of the same set of objects: bright field gray scale images, and three different fluoresccence channels to represent different photopigments. All four images show the same objects, but with different pixel intensities. It may be useful to combine information from all images into the segmentation process. This is requires customization of existing workflows in Phenopype, for which the low-throughput workflow is be suited best. Here we have access to intermediate output, and can also integrate low level functions from the `OpenCV` library. \n",
    "\n",
    "The appraoch is to load all images separately, do segmentation separately, find contours create four binary masks from all contour coordinates, combine the binary masks into a single image, find contours on the binary image.\n",
    "\n",
    "[1] https://docs.opencv.org/master/d0/d86/tutorial_py_image_arithmetics.html\n",
    "\n",
    "<center>\n",
    "<div style=\"width:800px; text-align: left\" >\n",
    "<img src=\"_figures/ex3_phyto_layers.png\">\n",
    "    \n",
    "**Fig. 1:** Each sample includes four images: 1 brightfield (top) and 3 fluorescence measurements (black, bottom). Due to different pigments, not all spcecies are visible in each image, because of different emission spectra. For example, the two long string shaped cells marked with the green circles only occur in two of the fluorescence channels, but not the third one or the brightfield. Therefore, including information from all images for segmentation may be useful to get close to the \"true\" cell count and community composition within a sample. \n",
    "    \n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape descriptors\n",
    "\n",
    "With the recently (phenopype 1.0.5) introducted `shape_features` function you can measure a set of 43 rotation invariant features from collected contours. However, depending on your case, you may not be able to make use of all feature descriptors since some of them are not scale, rotation or translation invariant. Refer to the documentation `help(pp.measurement.shape_features)` to see which features are useful. \n",
    "\n",
    "In our case, phytoplankton are scattered over the image, so we need descriptors that are at least translational and rotational invariants, whereas scale includes relevant descriptive power over phytoplankton of different sizes. Therefore we will use (some) of the basic shape descriptors and the seven Hu moments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function shape_features in module phenopype.core.measurement:\n",
      "\n",
      "shape_features(obj_input, df_contours=None, return_basic=True, return_moments=False, return_hu_moments=False)\n",
      "    Collects a set of 41 shape descriptors from every contour. There are three sets of \n",
      "    descriptors: basic shape descriptors, moments, and hu moments. Two additional features,\n",
      "    contour area and diameter are already provided by the find_contours function.\n",
      "    https://docs.opencv.org/3.4.9/d3/dc0/group__imgproc__shape.html\n",
      "    \n",
      "    Of the basic shape descriptors, all 10 are translational invariants, 8 are rotation \n",
      "    invariant (rect_height and rect_width are not) and  4 are also scale invariant \n",
      "    (circularity, compactness, roundness, solidity).\n",
      "    https://en.wikipedia.org/wiki/Shape_factor_(image_analysis_and_microscopy)  \n",
      "                                \n",
      "    The moments set encompasses 10 raw spatial moments (some are translation and rotation\n",
      "    invariants, but not all), 7 central moments (all translational invariant) and 7 central \n",
      "    normalized moments (all translational and scale invariant).\n",
      "    https://en.wikipedia.org/wiki/Image_moment\n",
      "    \n",
      "    The 7 hu moments are derived of the central moments, and are all translation, scale \n",
      "    and rotation invariant.\n",
      "    http://www.sci.utah.edu/~gerig/CS7960-S2010/handouts/Hu.pdf\n",
      "        \n",
      "    Basic shape descriptors:\n",
      "        circularity = 4 * np.pi * contour_area / contour_perimeter_length^2\n",
      "        compactness = âˆš(4 * contour_area / pi) / contour_diameter\n",
      "        min_rect_max = minimum bounding rectangle major axis\n",
      "        min_rect_min = minimum bounding rectangle minor axis\n",
      "        perimeter_length = total length of contour perimenter\n",
      "        rect_height = height of the bounding rectangle (\"caliper dim 1\")\n",
      "        rect_width = width of the bounding rectangle (\"caliper dim 2\")\n",
      "        roundness = (4 * contour_area) / pi * contour_perimeter_length^2\n",
      "        solidity = contour_area / convex_hull_area\n",
      "        tri_area = area of minimum bounding triangle\n",
      "    \n",
      "    Moments:\n",
      "        raw moments = m00, m10, m01, m20, m11, m02, m30, m21,  m12, m03\n",
      "        central moments = mu20, mu11, mu02, mu30, mu21, mu12, mu03,  \n",
      "        normalized central moments = nu20, nu11, nu02, nu30, nu21, nu12, nu03\n",
      "    \n",
      "    Hu moments:\n",
      "        hu moments = hu1, hu2, hu3, hu4, hu5, hu6, hu7\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    obj_input : array or container\n",
      "        input object\n",
      "    df_contours : DataFrame, optional\n",
      "        contains the contours\n",
      "    return_basic: True, opational\n",
      "        append the basic shape descriptors to a provided contour DataFrame\n",
      "    return_moments: False, optional\n",
      "        append the basic shape descriptors to a provided contour DataFrame\n",
      "    return_hu_moments: False, optional\n",
      "        append the basic shape descriptors to a provided contour DataFrame\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    df_contours : DataFrame or container\n",
      "        contains contours, and added features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import phenopype as pp\n",
    "\n",
    "help(pp.measurement.shape_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['isopods.jpg',\n",
       " 'isopods_fish.mp4',\n",
       " 'phyto_445.jpg',\n",
       " 'phyto_469.jpg',\n",
       " 'phyto_586.jpg',\n",
       " 'phyto_bright.jpg',\n",
       " 'snails1.jpg',\n",
       " 'snails2.jpg',\n",
       " 'stickle1.JPG',\n",
       " 'stickle2.JPG',\n",
       " 'stickle3.JPG',\n",
       " 'stickleback_side.jpg',\n",
       " 'stickleback_top.jpg',\n",
       " 'worms.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirpath defaulted to file directory - E:\\git_repos\\phenopype\\tutorials\\images\n",
      "Directory to save files set at - E:\\git_repos\\phenopype\\tutorials\\images\n",
      "dirpath defaulted to file directory - E:\\git_repos\\phenopype\\tutorials\\images\n",
      "Directory to save files set at - E:\\git_repos\\phenopype\\tutorials\\images\n",
      "dirpath defaulted to file directory - E:\\git_repos\\phenopype\\tutorials\\images\n",
      "Directory to save files set at - E:\\git_repos\\phenopype\\tutorials\\images\n",
      "dirpath defaulted to file directory - E:\\git_repos\\phenopype\\tutorials\\images\n",
      "Directory to save files set at - E:\\git_repos\\phenopype\\tutorials\\images\n"
     ]
    }
   ],
   "source": [
    "bright, df_bright = pp.load_image(\"images/phyto_bright.jpg\", df=True) ## df=True creates a \"backbone\" with meta-data\n",
    "fl445, df_fl445 = pp.load_image(\"images/phyto_445.jpg\", df=True)\n",
    "fl469, df_fl469 = pp.load_image(\"images/phyto_469.jpg\", df=True)\n",
    "fl586, df_fl586 = pp.load_image(\"images/phyto_586.jpg\", df=True)\n",
    "\n",
    "pp.show_image([bright, fl445, fl469, fl586], max_dim=1000, position_offset=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the segmentation - note that the brightfield image requires a different method than the fluorescence images, which can be run on the default settings (`method=\"binary, value=127`). However, they need to be inverted for the algorithm to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "bright_bin = pp.segmentation.threshold(bright, method=\"adaptive\", blocksize=299, constant=10) \n",
    "fl445_bin = pp.segmentation.threshold(fl445, invert=True, value=127) ## change \"value\" to increase or decrease sensitivity\n",
    "fl469_bin = pp.segmentation.threshold(fl469, invert=True)\n",
    "fl586_bin = pp.segmentation.threshold(fl586, invert=True)\n",
    "\n",
    "pp.show_image([bright_bin, fl445_bin, fl469_bin, fl586_bin], max_dim=1000, position_offset=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine all four images into a single array using `OpenCV`'s `add`: https://docs.opencv.org/master/d2/de8/group__core__array.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "comb = cv2.add(bright_bin,fl445_bin)\n",
    "comb = cv2.add(comb,fl469_bin)\n",
    "comb = cv2.add(comb,fl586_bin)\n",
    "\n",
    "pp.show_image([bright_bin, fl445_bin, fl469_bin, fl586_bin, comb], max_dim=1000, position_offset=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back in phenopype, we can detect contours, and calculate the shape features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contours = pp.segmentation.find_contours(comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick visualization of the found contours reveals that we probably have to detected some contours that are not phytoplankton, but image artefacts. It might be usefull at this point to set a minimum and maximum size in find contours - probably necessary to play around with this to get good results, I don't know enough about these images and phytoplankton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b6c4fdd108>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd.to_numeric(df_contours[\"area\"]).hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contours = pp.segmentation.find_contours(comb, min_area=10, max_area=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the shape features (basic and Hu):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contours = pp.measurement.shape_features(df_contours, return_hu_moments=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to visualize and save the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- canvas saved under _temp/output/ex3\\canvas_phyto_bright.jpg.jpg.\n",
      "- canvas saved under _temp/output/ex3\\canvas_phyto_445.jpg.jpg (overwritten).\n",
      "- canvas saved under _temp/output/ex3\\canvas_phyto_469.jpg.jpg (overwritten).\n",
      "- canvas saved under _temp/output/ex3\\canvas_phyto_586.jpg.jpg (overwritten).\n"
     ]
    }
   ],
   "source": [
    "viz_check = []\n",
    "\n",
    "for img, img_df in zip([bright, fl445, fl469, fl586],[df_bright, df_fl445, df_fl469, df_fl586]):\n",
    "    viz = pp.visualization.draw_contours(img, df_contours, fill=0, line_width=1)\n",
    "    viz_check.append(viz)\n",
    "    pp.export.save_canvas(viz, dirpath=\"_temp/output/ex3\", save_suffix=img_df[\"filename\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.show_image(viz_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- contours saved under _temp/output/ex3\\contours.csv.\n"
     ]
    }
   ],
   "source": [
    "pp.export.save_contours(df_contours, save_coords=False, dirpath=\"_temp/output/ex3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick PCA done in R shows that the shapes do separate out (features were centered + scaled). Not sure though why we get this funnel shape..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<div style=\"width:600px; text-align: left\" >\n",
    "<img src=\"_figures/ex3_coords_pca1.png\">\n",
    "\n",
    "</div>\n",
    "</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colour intensities (fluorescence)\n",
    "\n",
    "We can now use the extracted contours to extract pixel level information from the images. We have used the information from all images to determin the \"true\" shape, i.e. the space that each cell is occupying in the images. If we now use that information, and apply it back to the original images, we can measure the different intensities with which they fluores.\n",
    "\n",
    "\n",
    "<center>\n",
    "<div style=\"text-align: left\" >\n",
    "<img src=\"_figures/ex3_colour_intensities.png\">\n",
    "    \n",
    "**Fig. 2:** The boundaries of all phytoplankton cells were determined using information from all images. Within those contours we can now measure how cells fluores at different wavelengths (not the different intensities within the cells).\n",
    "    \n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- colours saved under _temp/output/ex3\\colours_phyto_445.jpg.csv.\n",
      "- colours saved under _temp/output/ex3\\colours_phyto_469.jpg.csv.\n",
      "- colours saved under _temp/output/ex3\\colours_phyto_586.jpg.csv.\n"
     ]
    }
   ],
   "source": [
    "intensities = []\n",
    "\n",
    "for img, img_df in zip([fl445, fl469, fl586],[df_fl445, df_fl469, df_fl586]):\n",
    "    intensity = pp.measurement.colour_intensity(img, img_df, df_contours)\n",
    "    pp.export.save_colours(intensity, dirpath=\"_temp/output/ex3\", save_suffix=img_df[\"filename\"][0])\n",
    "    intensities.append(intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[          filename  width  height  size_ratio_original contour gray_mean  \\\n",
       " 0    phyto_445.jpg   3135    2132                    1       1         4   \n",
       " 1    phyto_445.jpg   3135    2132                    1       2   1.31579   \n",
       " 2    phyto_445.jpg   3135    2132                    1       3   8.01163   \n",
       " 3    phyto_445.jpg   3135    2132                    1       4   4.53571   \n",
       " 4    phyto_445.jpg   3135    2132                    1       5   13.1957   \n",
       " ..             ...    ...     ...                  ...     ...       ...   \n",
       " 570  phyto_445.jpg   3135    2132                    1     571      6.12   \n",
       " 571  phyto_445.jpg   3135    2132                    1     572   11.0467   \n",
       " 572  phyto_445.jpg   3135    2132                    1     573   2.78626   \n",
       " 573  phyto_445.jpg   3135    2132                    1     574   12.6949   \n",
       " 574  phyto_445.jpg   3135    2132                    1     575  0.330658   \n",
       " \n",
       "       gray_sd  \n",
       " 0     1.49241  \n",
       " 1     1.45286  \n",
       " 2     3.47581  \n",
       " 3     2.51872  \n",
       " 4     5.85929  \n",
       " ..        ...  \n",
       " 570  0.587878  \n",
       " 571   6.58572  \n",
       " 572  0.873771  \n",
       " 573   3.24174  \n",
       " 574   0.47045  \n",
       " \n",
       " [575 rows x 7 columns],\n",
       "           filename  width  height  size_ratio_original contour gray_mean  \\\n",
       " 0    phyto_469.jpg   3135    2132                    1       1   29.1136   \n",
       " 1    phyto_469.jpg   3135    2132                    1       2   15.3158   \n",
       " 2    phyto_469.jpg   3135    2132                    1       3   35.5349   \n",
       " 3    phyto_469.jpg   3135    2132                    1       4   114.917   \n",
       " 4    phyto_469.jpg   3135    2132                    1       5   51.7935   \n",
       " ..             ...    ...     ...                  ...     ...       ...   \n",
       " 570  phyto_469.jpg   3135    2132                    1     571     17.12   \n",
       " 571  phyto_469.jpg   3135    2132                    1     572   50.9346   \n",
       " 572  phyto_469.jpg   3135    2132                    1     573    34.084   \n",
       " 573  phyto_469.jpg   3135    2132                    1     574   33.7635   \n",
       " 574  phyto_469.jpg   3135    2132                    1     575    34.313   \n",
       " \n",
       "       gray_sd  \n",
       " 0     7.69361  \n",
       " 1      3.7424  \n",
       " 2     12.1327  \n",
       " 3     67.5601  \n",
       " 4     16.6906  \n",
       " ..        ...  \n",
       " 570  0.930376  \n",
       " 571   22.2338  \n",
       " 572   8.78065  \n",
       " 573   5.70262  \n",
       " 574  0.807235  \n",
       " \n",
       " [575 rows x 7 columns],\n",
       "           filename  width  height  size_ratio_original contour gray_mean  \\\n",
       " 0    phyto_586.jpg   3135    2132                    1       1   7.13636   \n",
       " 1    phyto_586.jpg   3135    2132                    1       2   4.21053   \n",
       " 2    phyto_586.jpg   3135    2132                    1       3   7.95349   \n",
       " 3    phyto_586.jpg   3135    2132                    1       4   170.238   \n",
       " 4    phyto_586.jpg   3135    2132                    1       5   18.4565   \n",
       " ..             ...    ...     ...                  ...     ...       ...   \n",
       " 570  phyto_586.jpg   3135    2132                    1     571      4.24   \n",
       " 571  phyto_586.jpg   3135    2132                    1     572   13.9626   \n",
       " 572  phyto_586.jpg   3135    2132                    1     573   49.0687   \n",
       " 573  phyto_586.jpg   3135    2132                    1     574   9.65579   \n",
       " 574  phyto_586.jpg   3135    2132                    1     575   5.52006   \n",
       " \n",
       "       gray_sd  \n",
       " 0     3.25849  \n",
       " 1     2.04113  \n",
       " 2     5.80679  \n",
       " 3     85.1425  \n",
       " 4     7.60922  \n",
       " ..        ...  \n",
       " 570  0.618385  \n",
       " 571   8.34303  \n",
       " 572    22.671  \n",
       " 573   3.37256  \n",
       " 574  0.539751  \n",
       " \n",
       " [575 rows x 7 columns]]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intensities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "This analysis can probably easiest be conducted within the prototyping workflow, as currently there is no good way to implement it in the low or high throughput workflow. Something like this (in pseudo-code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## => create a directory tree where each directory has the 4 images (naming convention)\n",
    "## => loop over these directories\n",
    "\n",
    "## for d in dirlist:\n",
    "##    img = load_image()\n",
    "##    ...  \n",
    "##    preprocessing (morphology operation + blur) - shown in example 1 and 5 \n",
    "##    segmentation \n",
    "##    contours\n",
    "##    shape features\n",
    "##    colour intensity\n",
    "##    visualization + export to the same subdir\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
