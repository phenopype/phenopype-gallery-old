{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Measuring shape, size and colour of isopods  \n",
    "\n",
    "In this example I am demonstrating all three phenopype workflows, prototyping, low throughput, and high throughput. For a project, you would probably only use either the low or high throughput approach, depending on the amount of images, but the protoypting approach for this example decomposes the all the required steps for a classic computer vision workflow. \n",
    "\n",
    "Little nugget of information: this was the original computer vision problem that phenopype was intended to solve (it's predecessor [\"iso_cv\"](https://github.com/mluerig/iso_cv) was not much more than a script-collection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "**Related tutorials, examples and further reading**\n",
    "\n",
    "<ul>\n",
    "<li><a href=\"tutorial_2_phenopype_images.ipynb\">Tutorial 2: Interacting with images in phenopype</a></li>\n",
    "<li><a href=\"tutorial_3_phenopype_workflows.ipynb\">Tutorial 3: The three phenopype workflows</a></li>\n",
    "<li><a href=\"resources.html#computer-vision\">About the structure of digital images</a></li>\n",
    "<li><a href=\"https://docs.opencv.org/3.4.9/d9/d61/tutorial_py_morphological_ops.html\">About morphological operations</a></li>\n",
    "</ul>\n",
    "       \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"row; text-align: left\">\n",
    "    \n",
    "<div class=\"col-md-6\">\n",
    "    \n",
    "![Before](_assets/images/figures/ex1_before.jpg)\n",
    "    \n",
    "**Input** - Freshwater isopod, alive, photographed on a white resin-tray from a camera stand. \n",
    "</div>\n",
    "<div class=\"col-md-6\">\n",
    "\n",
    "![After](_assets/images/figures/ex1_after.jpg)\n",
    "    \n",
    "**Results** - Isopod shape, size and colour are extracted (and size referenced using the reference card) \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the image\n",
    "\n",
    "First we import the image from the a filepath using `load_image`. With the flag `df=True` we can extract some image-meta information that we want to be represented in the results files later (i.e. image name and its dimensions). After loading it, we can have a quick look at it with the `show_image` function - you can close it again with Enter or Esc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phenopype as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"images/isopods.jpg\"\n",
    "image, img_data = pp.load_image(filepath, df=True)\n",
    "pp.show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>size_ratio_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>isopods.jpg</td>\n",
       "      <td>2100</td>\n",
       "      <td>1400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename  width  height  size_ratio_original\n",
       "0  isopods.jpg   2100    1400                    1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data # size ratio refers whether this image has been resized using the resize argument of `load_image`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing a mask\n",
    "\n",
    "The original image has a lot of noise, e.g. the non-white area around the tray, water reflections, the label, the reference card, and the little fecal pellets that lie around on the tray. Classic computer vision algorithms are unspecific to the object, so they will pick up any object that is darker than its environment. Therefore, a useful preprocessing step is to exclude some of that noise by applying a mask. With the `create_mask` function, you can include or exclude certain areas of the image from the following analysis steps (`include=True/False`). \n",
    "\n",
    "Here, we want to include all of the wite tray that has isopods in it: Hold the left button down and drag the rectangle shaped mask tool over the area you want to include.\n",
    "\n",
    "<center>\n",
    "<div style=\"width:500px; text-align: left\" >\n",
    "    \n",
    "![Create masks](_assets/images/figures/masks1.gif)\n",
    "\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- create mask\n"
     ]
    }
   ],
   "source": [
    "masks = pp.preprocessing.create_mask(image,df_image_data=img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create size reference\n",
    "\n",
    "Within the area we masked lies the reference card. We want to include its information in our results files (the pixel-to-mm-ratio), so we supply the image meta DataFrame with `df_image_data=img_data`. However, we do not want the card itself to be detected, so we mask it with the argument `mask=True` and by supplying or mask DataFrame with `df_masks=masks` to have both masks in one place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<div style=\"width:500px; text-align: left\">\n",
    "    \n",
    "![Adding a scale](_assets/images/figures/ex1_scale.gif)\n",
    "    \n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- measure pixel-to-mm-ratio\n",
      "Scale set\n",
      "Scale set\n",
      "- add column length\n",
      "Template selected\n",
      "- scale pixel-to-mm-ratio already measured (overwrite=False)\n"
     ]
    }
   ],
   "source": [
    "img_data, masks = pp.preprocessing.create_scale(image, \n",
    "                                                mask=True,\n",
    "                                                df_image_data=img_data, \n",
    "                                                df_masks=masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `masks` DataFrame contains two masks: the one we created above that *includes* the tray and the one we made to *exclude* the scale reference card:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>size_ratio_original</th>\n",
       "      <th>mask</th>\n",
       "      <th>include</th>\n",
       "      <th>coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>isopods.jpg</td>\n",
       "      <td>2100</td>\n",
       "      <td>1400</td>\n",
       "      <td>1</td>\n",
       "      <td>mask1</td>\n",
       "      <td>True</td>\n",
       "      <td>[(220, 138), (1892, 138), (1892, 1353), (220, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>isopods.jpg</td>\n",
       "      <td>2100</td>\n",
       "      <td>1400</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>False</td>\n",
       "      <td>[(443, 1025), (688, 1025), (688, 1229), (443, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename  width  height  size_ratio_original   mask include  \\\n",
       "0  isopods.jpg   2100    1400                    1  mask1    True   \n",
       "0  isopods.jpg   2100    1400                    1  scale   False   \n",
       "\n",
       "                                              coords  \n",
       "0  [(220, 138), (1892, 138), (1892, 1353), (220, ...  \n",
       "0  [(443, 1025), (688, 1025), (688, 1229), (443, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now have a quick look at both masks together by calling the visualization function `draw_mask`, followed by `show_image`. For this we should create a new array and *not* overwrite the original image loaded before - here we call it `canvas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - show mask: mask1.\n",
      " - show mask: scale.\n"
     ]
    }
   ],
   "source": [
    "canvas = pp.visualization.draw_masks(image, df_masks=masks, line_width=3)\n",
    "pp.show_image(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation - 1st attempt\n",
    "\n",
    "Now that we have removed most of the noise, we can implement an algorithm that segments the imgae into foreground and background (check the [resources section](resources.html#computer-vision) of the documentation. Here we use the `threshold` algorithm that to detect the isopods as foreground and the tray as background. By supplying the mask DataFrame we created before with `df_masks=masks`, we can exclude the unwanted regions of the image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- include mask \"mask1\" pixels\n",
      "- exclude mask \"scale\" pixels\n"
     ]
    }
   ],
   "source": [
    "image_bin = pp.segmentation.threshold(image, df_masks=masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting array `image_bin` is a binary image where white regions are foreground and black background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.show_image(image_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good, but there is still a lot of noise inside the image (isopod fecal pellets) that we need to remove. Right now, all information about foreground and background is in \"pixel-space\", i.e. it's a drawn representation of the informative areas. To convert it to coordinate space, and in the later steps extract information from the raw image, we will use `find_contours` on this binary image. But setting the argument `min_area`, we can set a minimum size for the area that the contours should have - 100 pixels should be enough to exclude all fecal pellets. Again, we can supply the image meta DataFrame to concatenate existing information. Afterwards we can draw the contours onto `canvas` with `draw_contours` - the detected contours are in green. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contours = pp.segmentation.find_contours(image_bin, df_image_data=img_data, min_area=100) \n",
    "canvas = pp.visualization.draw_contours(canvas, df_contours=df_contours)\n",
    "pp.show_image(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation - 2nd attempt\n",
    "\n",
    "Now we have excluded all noise - but some isopods are not well deteced. Mostly the ones with lighter pigmenation, because the contrast they form agains the light background isn't strong enough. We can try a different threshold algorithm by setting the `method` argument: `\"adaptive\"` algorithms work particularly well with variable contrast levels and lighting. \n",
    "\n",
    "Additionally, instead of using the default gray channel (i.e. the average across all three colour channels), we can try to run the thresholding function on a single colour channel. The contrast and signal-to-noise-ratio can be different betweeen the channels. We can select a different channel using the `select_canvas` function - here I isolate all three colour channels, and supply them to `show_image` to show themm all at once, and to evaluate, which colour-channels is suited best: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- red channel\n",
      "- green channel\n",
      "- blue channel\n"
     ]
    }
   ],
   "source": [
    "r = pp.visualization.select_canvas(image, canvas=\"r\")\n",
    "g = pp.visualization.select_canvas(image, canvas=\"g\")\n",
    "b = pp.visualization.select_canvas(image, canvas=\"b\")\n",
    "pp.show_image([r,g,b], max_dim=500) ## max_dim=reduce window size to 500 pixels on any axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this suggests that the green colour channel will yield the best results: here, even the lighter pigmented isopods have a strong contrast against the tray. We can supply either `g` to `threshold`, or directly select this with the `channel` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- include mask \"mask1\" pixels\n",
      "- exclude mask \"scale\" pixels\n"
     ]
    }
   ],
   "source": [
    "image_bin = pp.segmentation.threshold(image, method=\"adaptive\", df_masks=masks, channel=\"green\")\n",
    "pp.show_image(image_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation - 3rd attempt\n",
    "\n",
    "Obviously we need to to tune a few things here, waay to many things are being detected. Currently the `\"adaptive\"` algorithm is on default sensitivity (`blocksize=99`), which we can reduce a bit. Also, we can increase the value for the constant to be subtracted after the tresholding with `constant`. We will try `blocksize=49` and `constant=5`. Afterwards, we plot the detected contours back onto the canvas of the original image, not the green channel image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<div style=\"width:800px; text-align: left\">\n",
    "\n",
    "![Binarization](_assets/images/figures/ex1_binarization.jpg)\n",
    "        \n",
    "**Figure 2** - Demonstration of blocksize (19, 99, 199 - left to right) and constant (1, 5 - top and bottom) parameters. Increasing blocksize leads to better structuring of the pixel level information contained in the image (i.e. larger \"blocks\" of connected pixels can be detected). This is computationally costly, so it will be slow for large images. Also, there is an optimal value beyond which detection performance will decrease. \n",
    "\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- include mask \"mask1\" pixels\n",
      "- exclude mask \"scale\" pixels\n"
     ]
    }
   ],
   "source": [
    "image_bin = pp.segmentation.threshold(image, method=\"adaptive\", blocksize=49, \n",
    "                                      constant=5, df_masks=masks, channel=\"green\")\n",
    "df_contours = pp.segmentation.find_contours(image_bin, df_image_data=img_data, min_area=100)\n",
    "canvas = pp.visualization.draw_contours(image, df_contours=df_contours, line_width=1)\n",
    "pp.show_image(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation - final product\n",
    "\n",
    "That looks pretty good. The last thing we need to take care of are the appendages (we don't want to include those) and the gaps that sometimes form between the segments (we want to have that error to be consistent towards no gaps). Some blurring, and a morphological operation will do the trick. Blurring will smooth the contour of the isopods, and a farly large `\"cross\"` shaped kernel will \"cut off\" the appendages and other long structures in the binary image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- include mask \"mask1\" pixels\n",
      "- exclude mask \"scale\" pixels\n",
      " - show mask: mask1.\n",
      " - show mask: scale.\n"
     ]
    }
   ],
   "source": [
    "image_blurred = pp.segmentation.blur(image, kernel_size = 15)\n",
    "image_bin = pp.segmentation.threshold(image_blurred, method=\"adaptive\", blocksize=49, \n",
    "                                      constant=5, df_masks=masks,  channel=\"green\")\n",
    "image_morph = pp.segmentation.morphology(image_bin, operation=\"open\", shape=\"cross\", \n",
    "                                         kernel_size = 9, iterations=2)\n",
    "\n",
    "contours = pp.segmentation.find_contours(image_morph, df_image_data=img_data, min_area=250)\n",
    "canvas = pp.visualization.draw_masks(image, df_masks=masks, line_width=3)\n",
    "canvas = pp.visualization.draw_contours(canvas, df_contours=contours, line_width=1)\n",
    "pp.show_image(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring colour\n",
    "\n",
    "Ok, this looks good - we now have a DataFrame with the contour-data of all 20 isopods, including their length (`diameter` of the enclosing circle), and the shape (`coords`). Using this information, we can finally extract the colour information from inside the contours. To do so we can supply the original image array along with the contour DataFrame to the `colour_intensity` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pigmentation = pp.measurement.colour_intensity(image, df_image_data=img_data, df_contours=contours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export\n",
    "\n",
    "Done - we can now save the contours and the colour information to csv, as well as the canvas for quality control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- contours saved under _temp/output/ex1\\contours.csv (overwritten).\n",
      "- colours saved under _temp/output/ex1\\colours.csv.\n",
      "- canvas saved under _temp/output/ex1\\canvas.jpg (overwritten).\n"
     ]
    }
   ],
   "source": [
    "pp.export.save_contours(contours, dirpath=r\"_temp/output/ex1\")\n",
    "pp.export.save_colours(pigmentation, dirpath=r\"_temp/output/ex1\")\n",
    "pp.export.save_canvas(canvas, dirpath=r\"_temp/output/ex1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low throughput\n",
    "\n",
    "In the low throughput approach we will apply the very same functions as in the prototyping approach. However, we use the knowledge acquired before (i.e. good settings for the segmentation functions). Notice that less objects are created because the intermediate output is stored in the container. This makes for a cleaner workspace, but may conceal which steps have already been performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phenopype as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load image. The container also has a `load` method with which we can attempt to load previously stored input, such as masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTOLOAD\n",
      "- masks.csv\n"
     ]
    }
   ],
   "source": [
    "filepath = r\"images/isopods.jpg\"\n",
    "\n",
    "ct = pp.load_image(filepath, cont=True) ## load image as container\n",
    "\n",
    "ct.load(dirpath=r\"_temp/output/ex1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask the edges of the tray, measure the reference card, and mask it. If masks have been loaded by the step above, this is skipped (unless `overwrite=True`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- mask with label mask1 already created (overwrite=False)\n",
      "- measure pixel-to-mm-ratio\n",
      "Scale set\n",
      "- add column length\n",
      "Template selected\n",
      "- scale template mask already created (overwrite=False)\n",
      "- scale pixel-to-mm-ratio already measured (overwrite=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>size_ratio_original</th>\n",
       "      <th>mask</th>\n",
       "      <th>include</th>\n",
       "      <th>coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>isopods.jpg</td>\n",
       "      <td>2100</td>\n",
       "      <td>1400</td>\n",
       "      <td>1</td>\n",
       "      <td>mask1</td>\n",
       "      <td>True</td>\n",
       "      <td>[(252, 197), (1917, 197), (1917, 1345), (252, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>isopods.jpg</td>\n",
       "      <td>2100</td>\n",
       "      <td>1400</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>False</td>\n",
       "      <td>[(457, 1023), (680, 1023), (680, 1227), (457, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename  width  height  size_ratio_original   mask  include  \\\n",
       "0  isopods.jpg   2100    1400                    1  mask1     True   \n",
       "1  isopods.jpg   2100    1400                    1  scale    False   \n",
       "\n",
       "                                              coords  \n",
       "0  [(252, 197), (1917, 197), (1917, 1345), (252, ...  \n",
       "1  [(457, 1023), (680, 1023), (680, 1227), (457, ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.preprocessing.create_mask(ct)\n",
    "pp.preprocessing.create_scale(ct, template=True)\n",
    "\n",
    "ct.df_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we first have to select the canvas, then we can draw the mask onto the canvas and finally show it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- raw image\n",
      " - show mask: mask1.\n",
      " - show mask: scale.\n"
     ]
    }
   ],
   "source": [
    "pp.visualization.select_canvas(ct, canvas=\"raw\")\n",
    "pp.visualization.draw_masks(ct)\n",
    "pp.show_image(ct.canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First blur the image, then use `threshold` to segment it. Note that any masks in the container will be automatically applied. Afterwards, morphology operations are applied to the binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- include mask \"mask1\" pixels\n",
      "- exclude mask \"scale\" pixels\n"
     ]
    }
   ],
   "source": [
    "pp.segmentation.blur(ct, kernel_size = 15)\n",
    "pp.segmentation.threshold(ct, method=\"adaptive\", blocksize=49, \n",
    "                                      constant=5, channel=\"green\")\n",
    "pp.segmentation.morphology(ct, operation=\"open\", shape=\"cross\", \n",
    "                                         kernel_size = 9, iterations=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the contours..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.segmentation.find_contours(ct, min_area=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... draw them onto the canvas, and show them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.visualization.draw_contours(ct)\n",
    "pp.show_image(ct.canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use container's builtin autosave function `save` and export all contours and masks and the canvas. If you don't set the `dirpath` argument it will save all files to the directory that the original image is located in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTOSAVE\n",
      "save_canvas\n",
      "- canvas saved under _temp/output/ex1\\canvas.jpg (overwritten).\n",
      "save_contours\n",
      "- contours not saved - file already exists (overwrite=False).\n",
      "save_masks\n",
      "- masks not saved - file already exists (overwrite=False).\n",
      "save_scale\n",
      "- save scale to attributes\n"
     ]
    }
   ],
   "source": [
    "ct.save(dirpath = r\"_temp/output/ex1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** if you need to redo an analysis using the container, you should reset it with it's builtin `reset` method. Otherwise you may end up trying to binarize an image that is already binary, which will give unexpected, wront results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method save in module phenopype.utils:\n",
      "\n",
      "save(dirpath=None, overwrite=False, **kwargs) method of phenopype.utils.container instance\n",
      "    Autosave function for container. \n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    dirpath: str, optional\n",
      "        provide a custom directory where files should be save - overwrites \n",
      "        dirpath provided from container, if applicable\n",
      "    export_list: list, optional\n",
      "        used in pype rountine to check against already performed saving operations.\n",
      "        running container.save() with an empty export_list will assumed that nothing\n",
      "        has been saved so far, and will try \n",
      "    overwrite : bool, optional\n",
      "        gloabl overwrite flag in case file exists\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ct.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High throughput\n",
    "\n",
    "Now we will use the `pype` method to detect the isopods. For more information on how to analyze multiple images and whole datasets with this approach, check [Tutorial 3](tutorial_3_phenopype_workflow.ipynb), [Tutorial 4](tutorial_4_managing_projects.ipynb) and [Example 2](example_2_landmarks_stickleback.ipynb).\n",
    "\n",
    "<center>\n",
    "<div style=\"width:600px; text-align: left\" >\n",
    "    \n",
    "![Phenopype high throughput workflow](_assets/images/figures/workflow_high.png)\n",
    "    \n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of the pype method is to control the image analysis workflow from within a configuration file. While you modify that file, saving the changes will immediately update the reiterate the contained functions and show the results. After you finish, all settings needed to reproduce the results will be contained inside the configuration file. \n",
    "\n",
    "The `pype` can be initialized with the path to the image, and a name that will be appended to all results-files and the the configuration file that is created. Providing different names allows you to run and save multiple analyses side by side. Here we will use the `object_detection_morph` template, which contains preset instructions for object detection and morphology operations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phenopype as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirpath defaulted to file directory - E:\\git_repos\\phenopype\\tutorials\\images\n",
      "Directory to save files set at - E:\\git_repos\\phenopype\\tutorials\\images\n",
      "_temp/output/ex1\\pype_config_iso1.yaml\n",
      "\n",
      "\n",
      "------------+++ new pype iteration 2020:05:11 12:28:26 +++--------------\n",
      "\n",
      "\n",
      "AUTOLOAD\n",
      "- current scale information loaded from attributes.yaml\n",
      "- masks_iso1.csv\n",
      "PREPROCESSING\n",
      "create_mask\n",
      "- mask with label mask1 already created (overwrite=False)\n",
      "create_scale\n",
      "- scale pixel-to-mm-ratio already measured (overwrite=False)\n",
      "SEGMENTATION\n",
      "blur\n",
      "threshold\n",
      "- include mask \"mask1\" pixels\n",
      "morphology\n",
      "find_contours\n",
      "VISUALIZATION\n",
      "select_canvas\n",
      "- invalid selection - defaulting to raw image\n",
      "draw_contours\n",
      "EXPORT\n",
      "save_contours\n",
      "- contours saved under _temp/output/ex1\\contours_iso1.csv (overwritten).\n",
      "AUTOSAVE\n",
      "save_canvas\n",
      "- canvas saved under _temp/output/ex1\\canvas_iso1.jpg (overwritten).\n",
      "save_masks\n",
      "- masks not saved - file already exists (overwrite=False).\n",
      "save_scale\n",
      "- save scale to attributes (overwriting)\n",
      "\n",
      "\n",
      "TERMINATE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<phenopype.main.pype at 0x29251674388>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = r\"images/isopods.jpg\"\n",
    "\n",
    "pp.pype(filepath, name=\"iso1\", config_preset=\"object_detection_morph\", dirpath=r\"_temp/output/ex1\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If course, this default template does not come with the settings we have laboriously determined in the steps above - so we need to modify the settings in the configuration file. You can do so by simply changing according to our previous settings. For example:\n",
    "\n",
    "`pp.segmentation.threshold(ct, method=\"adaptive\", blocksize=49, constant=5, channel=\"green\")`\n",
    "\n",
    "becomes\n",
    "\n",
    "```\n",
    "- threshold:\n",
    "    method: adaptive\n",
    "    blocksize: 49\n",
    "    constant: 5\n",
    "    channel: green\n",
    "```\n",
    "    \n",
    "We also need to add a preprocessing section to draw a mask and scale:    \n",
    "\n",
    "```\n",
    "preprocessing:\n",
    "- create_mask\n",
    "- create_scale\n",
    "```\n",
    "\n",
    "Read more on how YAML-syntax works in the [corresponding section in Tutorial 2](tutorial_3_phenopype_workflows.ipynb#YAML-syntax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, the appropriate settings for this example are contained in a preset template named `ex1`, which we can supply directly to the `pype`. Note that we need to rename this run, otherwise the `pype` will reload our old settings (you can also just delete them in the folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "preprocessing:\n",
      "- create_mask\n",
      "- create_scale:\n",
      "    mask: true\n",
      "segmentation:\n",
      "- blur:\n",
      "    kernel_size: 15\n",
      "- threshold:\n",
      "    method: adaptive\n",
      "    blocksize: 49\n",
      "    constant: 5\n",
      "    channel: green\n",
      "- morphology:\n",
      "    operation: open\n",
      "    shape: cross\n",
      "    kernel_size: 9\n",
      "    iterations: 2\n",
      "- find_contours:\n",
      "    retrieval: ccomp\n",
      "    min_diameter: 0\n",
      "    min_area: 250\n",
      "visualization:\n",
      "- select_canvas:\n",
      "    canvas: image\n",
      "- draw_contours:\n",
      "    line_width: 2\n",
      "    label_width: 1\n",
      "    label_size: 1\n",
      "    fill: 0.3\n",
      "export:\n",
      "- save_contours:\n",
      "    overwrite: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pp.presets.ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirpath defaulted to file directory - E:\\git_repos\\phenopype\\tutorials\\images\n",
      "Directory to save files set at - E:\\git_repos\\phenopype\\tutorials\\images\n",
      "Did not find \"pype_config_iso2.yaml\" -  create at following location? (y/n):\n",
      "_temp/output/ex1\\pype_config_iso2.yaml\n",
      "y\n",
      "pype config generated from ex1.\n",
      "Created and saved new pype config \"pype_config_iso2.yaml\" in folder _temp/output/ex1\n",
      "_temp/output/ex1\\pype_config_iso2.yaml\n",
      "\n",
      "\n",
      "------------+++ new pype iteration 2020:05:11 12:28:46 +++--------------\n",
      "\n",
      "\n",
      "AUTOLOAD\n",
      "- current scale information loaded from attributes.yaml\n",
      "PREPROCESSING\n",
      "create_mask\n",
      "- create mask\n",
      "create_scale\n",
      "- scale pixel-to-mm-ratio already measured (overwrite=False)\n",
      "SEGMENTATION\n",
      "blur\n",
      "threshold\n",
      "- include mask \"mask1\" pixels\n",
      "morphology\n",
      "find_contours\n",
      "VISUALIZATION\n",
      "select_canvas\n",
      "- invalid selection - defaulting to raw image\n",
      "draw_contours\n",
      "EXPORT\n",
      "save_contours\n",
      "- contours saved under _temp/output/ex1\\contours_iso2.csv.\n",
      "AUTOSAVE\n",
      "save_canvas\n",
      "- canvas saved under _temp/output/ex1\\canvas_iso2.jpg.\n",
      "save_masks\n",
      "- masks saved under _temp/output/ex1\\masks_iso2.csv.\n",
      "save_scale\n",
      "- save scale to attributes (overwriting)\n",
      "\n",
      "\n",
      "TERMINATE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<phenopype.main.pype at 0x2925187fa08>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.pype(filepath, name=\"iso2\", config_preset=\"ex1\", dirpath=r\"_temp/output/ex1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
